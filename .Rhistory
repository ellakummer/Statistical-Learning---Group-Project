install.packages(c("leaps", "tree"))
my_data <- heart_datas
heart_datas <- read.csv("~/GitHub/Statistical-Learning---Group-Project/heart_datas.txt")
View(heart_datas)
my_data <- heart_datas
names(my_data)
attach(my_data)
# training set (we take half of our datas) :
train=sample(303,101)
# we apply a linear regression :
lm.fit=lm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data,subset=train)
# test (test error MSE) :
mean((target-predict(lm.fit,my_data))[-train]^2)
attach(my_data)
set.seed(1)
# training set (we take half of our datas) :
train=sample(303,101)
# we apply a linear regression :
lm.fit=lm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data,subset=train)
# test (test error MSE) :
mean((target-predict(lm.fit,my_data))[-train]^2)
View(my_data)
heart_datas <- read.csv("~/GitHub/Statistical-Learning---Group-Project/heart_datas.txt")
View(heart_datas)
my_data <- heart_datas
names(my_data)
attach(my_data)
set.seed(1)
# training set (we take half of our datas) :
train=sample(303,101)
# we apply a linear regression :
lm.fit=lm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data,subset=train)
# test (test error MSE) :
mean((target-predict(lm.fit,my_data))[-train]^2)
summary(lm.fit)
# GENERAL FORM :
glm.fit=glm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data,subset=train)
# CROSS VALIDATION :
glm.fit2=glm(targe,data=my_data)
# GENERAL FORM :
glm.fit=glm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data,subset=train)
# informations about the regression :
coef(glm.fit)
summary(glm.fit)
# test (test error MSE) :
mean((target-predict(lm.fit,my_data))[-train]^2)
summary(lm.fit)
# GENERAL FORM :
glm.fit=glm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data,subset=train)
# informations about the regression :
coef(glm.fit)
summary(glm.fit)
# test error MSE :
mean((target-predict(glm.fit,my_data, type="response"))[-train]^2)
# CROSS VALIDATION :
glm.fit2=glm(target~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=my_data)
set.seed(17)
# K = 10
library(boot)
cv.error.10=cv.glm(my_data,glm.fit2,K=10)$delta[1]
cv.error.10
# leave-one-out cross validation :
cv.error=cv.glm(my_data,glm.fit2)$delta[1]
cv.error
# CLASSIFICATION  tree :
library(tree)
disease=ifelse(target<=0.5,"No","Yes")
my_data_2=data.frame(my_data,disease)
tree.datas=tree(disease~.-target,my_data_2)
summary(tree.datas)
plot(tree.datas)
text(tree.datas,pretty=0)
tree.datas
# error test classification tree :
set.seed(2)
train=sample(1:nrow(my_data_2), 150)
my_data_2.test=my_data_2[-train,]
disease.test=disease[-train]
tree.datas=tree(disease~.-target,my_data_2,subset=train)
tree.pred=predict(tree.datas,my_data_2.test,type="class")
table(tree.pred,disease.test)
# PRUNNING TREE
set.seed(3)
cv.prune.datas=cv.tree(tree.datas,FUN=prune.misclass)
cv.prune.datas
par(mfrow=c(1,2))
prune.datas=prune.misclass(tree.datas,best=9)
plot(prune.datas)
plot(prune.datas)
text(prune.datas,pretty=0)
# error test prunning tree :
tree.pred2=predict(prune.datas,my_data_2.test,type="class")
table(tree.pred2,disease.test)
install.packages("leaps")
library(leaps)
regfit.full=regsubsets(target~.,data=my_data,nvmax=13)
# to predict the salary, we found these predictors in the Hitters components set:
reg.summary=summary (regfit.full)
reg.summary
# models:
names(reg.summary)
# USELESS ??
# we want according to adjusted R2, BIC, Cp
reg.summary$adjr2
reg.summary$bic
reg.summary$cp
reg.summary$rsq
par(mfrow=c(2,2))
# USELESS ??
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
which.max(reg.summary$adjr2)
points(10,reg.summary$adjr2[10], col="red",cex=2,pch=20)
coef(regfit.full ,10)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
which.min(reg.summary$cp)
points(9,reg.summary$cp[9],col="red",cex=2,pch=20)
coef(regfit.full ,9)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
which.min(reg.summary$bic)
points(7,reg.summary$bic[7],col="red",cex=2,pch=20)
coef(regfit.full ,7)
# Show some plots to provide evidence :
# USELESS ??  don't like how it's plot
plot(regfit.full,scale="r2")
plot(regfit.full,scale="adjr2")
plot(regfit.full,scale="Cp")
plot(regfit.full,scale="bic")
set.seed(1)
train2=sample(c(TRUE,FALSE), nrow(my_data),rep=TRUE)
test2=(!train2)
regfit.best=regsubsets(target~.,data=my_data[train2,],nvmax=13)
test.mat=model.matrix(target~.,data=my_data[test2,])
val.errors=rep(NA,13)
for(i in 1:13){
coefi=coef(regfit.best,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((my_data$target[test2]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,8)
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k=10
set.seed(1)
folds=sample(1:k,nrow(my_data),replace=TRUE)
cv.errors=matrix(NA,k,13, dimnames=list(NULL, paste(1:13)))
for(j in 1:k){
best.fit=regsubsets(target~.,data=my_data[folds!=j,],nvmax=13)
for(i in 1:13){
pred=predict(best.fit,my_data[folds==j,],id=i)
cv.errors[j,i]=mean( (my_data$target[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors
which.min(mean.cv.errors)
par(mfrow=c(1,1))
plot(mean.cv.errors,type='b')
reg.best=regsubsets(target~.,data=my_data, nvmax=13)
coef(reg.best,11)
coef(reg.best,7)
# ---------------------------------------------------------------
# ---------------------------------------------------------------
# ---------------------NON LINEAR MODELING ----------------------
# see tuto5 !! :)
# see tuto5 !! :)
# see tuto5 !! :)
# see tuto5 !! :)
# see tuto5 !! :)
# see tuto5 !! :)
heart_datas <- read.csv("~/GitHub/Statistical-Learning---Group-Project/heart_datas.txt")
View(heart_datas)
